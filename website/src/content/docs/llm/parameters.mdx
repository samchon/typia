---
title: Guide Documents > Large Language Model > parameters() function
---
import { Callout, Tabs } from "nextra/components";

import LocalSource from "../../../components/LocalSource";

## `parameters()` function

<Tabs items={[
    <code>typia</code>,
    <code>ILlmApplication</code>,
    <code>ILlmFunction</code>,
    <code>ILlmSchema</code>,
  ]}>
  <Tabs.Tab>
```typescript filename="typia" showLineNumbers {11-14}
export namespace llm {
  // LLM FUNCTION CALLING APPLICATION SCHEMA
  export function application<
    App extends Record<string, any>,
    Config extends Partial<ILlmSchema.IConfig> = {},
  >(
    config?: Partial<Pick<ILlmApplication.IConfig, "separate">>,
  ): ILlmApplication;

  // STRUCTURED OUTPUT
  export function parameters<
    Parameters extends Record<string, any>,
    Config extends Partial<ILlmSchema.IConfig> = {},
  >(): ILlmSchema.IParameters;

  // TYPE SCHEMA
  export function schema<
    T,
    Config extends Partial<ILlmSchema.IConfig> = {},
  >(
    $defs: Record<string, ILlmSchema>,
  ): ILlmSchema;
}
```
  </Tabs.Tab>
  <Tabs.Tab>
    <LocalSource
      path="packages/interface/src/schema/ILlmApplication.ts"
      filename="@typia/interface"
      showLineNumbers />
  </Tabs.Tab>
  <Tabs.Tab>
    <LocalSource
      path="packages/interface/src/schema/ILlmFunction.ts"
      filename="@typia/interface"
      showLineNumbers />
  </Tabs.Tab>
  <Tabs.Tab>
    <LocalSource
      path="packages/interface/src/schema/ILlmSchema.ts"
      filename="@typia/interface"
      showLineNumbers />
  </Tabs.Tab>
</Tabs>

Structured output schema of LLM (Large Language Model).

`typia.llm.parameters<Parameters>()` is a function generating structured output of LLM (Large Language Model) from a TypeScript object type. It is used to LLM function calling or structured output feature provided by OpenAI like LLM providers.

Return value type `ILlmSchema.IParameters` is a similar with the JSON schema definition's object type.
  
<Callout type="info">
**LLM Function Calling** and **Structured Output**

LLM selects proper function and fill arguments.

In nowadays, most LLM (Large Language Model) like OpenAI are supporting "function calling" feature. The "LLM function calling" means that LLM automatically selects a proper function and fills parameter values from conversation with the user (may by chatting text).

Structured output is another feature of LLM. The "structured output" means that LLM automatically transforms the output conversation into a structured data format like JSON.

- https://platform.openai.com/docs/guides/function-calling
- https://platform.openai.com/docs/guides/structured-outputs
</Callout>

<Tabs items={["TypeScript Source Code", "Compiled JavaScript"]}>
  <Tabs.Tab>
    <LocalSource 
      path="examples/src/llm/parameters.ts"
      filename="example/src/llm/parameters.ts"
      showLineNumbers />
  </Tabs.Tab>
  <Tabs.Tab>
    <LocalSource 
      path="examples/bin/llm/parameters.js"
      filename="example/bin/llm/parameters.js"
      showLineNumbers />
  </Tabs.Tab>
</Tabs>

[üìñ Playground Link](/playground/?script=JYWwDg9gTgLgBAbzgSQDIBsQGUDGALAUxAEM4BfOAMyghDgCIABAZ2JHwgDsB6CMAzsTDB6AbgBQoSLDgwAnsOIAaRLOIBzZuSo069eYrHi4kzjAJRKxHARQBZIgCMLiY3CLFg6AFxxmMKGBOdTgAMjVNADoAMWgSGAAeeg8vegA+CTg4QRACX39A4My4DTzsgFcQZyhivAhHR2ACZnyAoPUAbQBdYoArCCCCABMAfWIYVsKQ8JgNZhi48aSh8YJ0iTJxHC5-ODBfNExcQhJI5AAFYig2AnMoLQBeWQVgYkj0TEiwK5u75gTkA4qhY0gAKACUEm2nGYEHQBHeEHUoLAkKAA)

## Structured Output

```typescript filename="src/examples/llm.parameters.ts" copy showLineNumbers {4-10, 36}
import OpenAI from "openai";
import typia, { tags } from "typia";

interface IMember {
  email: string & tags.Format<"email">;
  name: string;
  age: number;
  hobbies: string[];
  joined_at: string & tags.Format<"date">;
}

const main = async (): Promise<void> => {
  const client: OpenAI = new OpenAI({
    apiKey: TestGlobal.env.CHATGPT_API_KEY,
    // apiKey: "<YOUR_OPENAI_API_KEY>",
  });
  const completion: OpenAI.ChatCompletion =
    await client.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "user",
          content: [
            "I am a new member of the community.",
            "",
            "My name is John Doe, and I am 25 years old.",
            "I like playing basketball and reading books,",
            "and joined to this community at 2022-01-01.",
          ].join("\n"),
        },
      ],
      response_format: {
        type: "json_schema",
        json_schema: {
          name: "member",
          schema: typia.llm.parameters<IMember>() as any,
        },
      },
    });
  console.log(JSON.parse(completion.choices[0].message.content!));
};
main().catch(console.error);
```

> ```bash filename="Terminal"
> {
>   email: 'john.doe@example.com',
>   name: 'John Doe',
>   age: 25,
>   hobbies: [ 'playing basketball', 'reading books' ],
>   joined_at: '2022-01-01'
> }
> ```

You can utilize the `typia.llm.parameters<Parameters>()` function to generate structured output like above.

Just configure output mode as JSON schema, and deliver the `typia.llm.parameters<Parameters>()` function returned value to the LLM provider like OpenAI (ChatGPT). Then, the LLM provider will automatically transform the output conversation into a structured data format of the `Parameters` type.

## Validation Feedback

Use [`typia.validate<T>()`](/docs/validators/validate) for validation feedback on structured output. When validation fails, the error can be formatted with inline `// ‚ùå` comments at each invalid property:

```json
{
  "name": "John",
  "age": "twenty", // ‚ùå [{"path":"$input.age","expected":"number"}]
  "email": "not-an-email", // ‚ùå [{"path":"$input.email","expected":"string & Format<\"email\">"}]
  "hobbies": "reading" // ‚ùå [{"path":"$input.hobbies","expected":"Array<string>"}]
}
```

The LLM reads this feedback and self-corrects on the next turn.

In the [AutoBe](https://github.com/wrtnlabs/autobe) project (AI-powered backend code generator), `qwen3-coder-next` showed only 6.75% raw function calling success rate on compiler AST types. However, with validation feedback, it reached 100%.

Working on compiler AST means working on any type and any use case.

  - [AutoBeDatabase](https://github.com/wrtnlabs/autobe/blob/main/packages/interface/src/database/AutoBeDatabase.ts)
  - [AutoBeOpenApi](https://github.com/wrtnlabs/autobe/blob/main/packages/interface/src/openapi/AutoBeOpenApi.ts)
  - [AutoBeTest](https://github.com/wrtnlabs/autobe/blob/main/packages/interface/src/test/AutoBeTest.ts)

```typescript filename="AutoBeTest.IExpression" showLineNumbers
// Compiler AST may be the hardest type structure possible
//
// Unlimited union types + unlimited depth + recursive references
export type IExpression =
  | IBooleanLiteral
  | INumericLiteral
  | IStringLiteral
  | IArrayLiteralExpression   // <- recursive (contains IExpression[])
  | IObjectLiteralExpression  // <- recursive (contains IExpression)
  | INullLiteral
  | IUndefinedKeyword
  | IIdentifier
  | IPropertyAccessExpression // <- recursive
  | IElementAccessExpression  // <- recursive
  | ITypeOfExpression         // <- recursive
  | IPrefixUnaryExpression    // <- recursive
  | IPostfixUnaryExpression   // <- recursive
  | IBinaryExpression         // <- recursive (left & right)
  | IArrowFunction            // <- recursive (body is IExpression)
  | ICallExpression           // <- recursive (args are IExpression[])
  | INewExpression            // <- recursive
  | IConditionalPredicate     // <- recursive (then & else branches)
  | ... // 30+ expression types total
```

## Restrictions

`typia.llm.parameters<Parameters>()` follows the same restrictions [`typia.llm.schema<T>()`](../schema) function. Also, it has only one additional restriction; the keyworded argument.

In the LLM function calling and structured output, the parameters must be a keyworded object type with static keys without any dynamic keys. Also, the object type must not be nullable or optional.

If you don't follow the LLM's keyworded arguments rule, `typia.llm.parameters<Parameters>()` will throw compilation error like below.

<Tabs items={["TypeScript Source Code", "Console Output"]}>
  <Tabs.Tab>
```typescript filename="src/examples/llm.parameters.violation.ts" showLineNumbers
import typia from "typia";

typia.llm.parameters<string>();
typia.llm.parameters<Record<string, boolean>>();
typia.llm.parameters<Array<number>>();
```
  </Tabs.Tab>
  <Tabs.Tab>
```bash filename="Terminal"
src/examples/llm.parameters.violation.ts:3:1 - error TS(typia.llm.parameters): unsupported type detected

- string
  - LLM parameters must be an object type.

3 typia.llm.parameters<string>();
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

src/examples/llm.parameters.violation.ts:3:22 - error TS2344: Type 'string' does not satisfy the constraint 'Record<string, any>'.

3 typia.llm.parameters<string>();
                       ~~~~~~

src/examples/llm.parameters.violation.ts:4:1 - error TS(typia.llm.parameters): unsupported type detected

- Recordstringboolean
  - LLM parameters must be an object type.

- Recordstringboolean
  - LLM parameters must not have dynamic keys.

4 typia.llm.parameters<Record<string, boolean>>();
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

src/examples/llm.parameters.violation.ts:5:1 - error TS(typia.llm.parameters): unsupported type detected

- Arraynumber
  - LLM parameters must be an object type.

5 typia.llm.parameters<Array<number>>();
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Found 4 errors in the same file, starting at: src/examples/llm.parameters.violation.ts
```
  </Tabs.Tab>
</Tabs>
